{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Report  \n",
    "Darrell Cenido and Jon Larson  \n",
    "CPSC 322, Fall 2025\n",
    "\n",
    "## Introduction\n",
    "The dataset we are using is a [Spotify track dataset](https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-600k-tracks) from Kaggle that contains attributes such as popularity (which we are planning on classifying), danceability, duration_ms, artists, explicit, energy, release_date, etc.  \n",
    "\n",
    "[We are planning on using the attributes mentioned above to help classify how popular a track is.]\n",
    "\n",
    "> add a brief description of findings (e.g., what classifier approach performed the best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "> Data Analysis: This section must provide details about the dataset. You must include:\n",
    "> 1. Information about the dataset itself, e.g., the attributes and attribute types, the number of instances, and the attribute being used as the label.\n",
    "> 1. Relevant summary statistics about the dataset.\n",
    "> 1. Data visualizations highlighting important/interesting aspects of your dataset. Visualizations may include frequency distributions, comparisons of attributes (scatterplot, multiple frequency diagrams), box and whisker plots, etc. The goal is not to include all possible diagrams, but instead to select and highlight diagrams that provide insight about the dataset itself.\n",
    "> 1. Note that this section must describe the above (in paragraph form) and not just provide diagrams and statistics. Also, each figure included must have a figure caption (Figure number and textual description) that is referenced from the text (e.g., “Figure 2 shows a frequency diagram for ...”).\n",
    "\n",
    "The Spotify dataset contains approximately 600,000 tracks, including attributes such as danceability, energy, duration_ms, explicit (boolean), release_date, and popularity (our classification label). The attributes include numeric features (e.g., danceability, duration_ms, energy), categorical features (e.g., explicit), string fields (e.g., artists), and date fields (release_date). For classification, we focus primarily on the numeric musical features because they are most consistently available across instances.\n",
    "\n",
    "Our target variable is popularity, an integer from 0 to 100. Because popularity is a continuous score, we convert it into categories representing low (0-33), medium (34-66), and high (67-100) popularity. This makes popularity suitable for classification models.\n",
    "\n",
    "To better understand the dataset, we computed basic summary statistics. The numeric attributes, such as danceability and energy, follow roughly bell-shaped distributions centered around mid-range values. Duration_ms, however, is strongly right-skewed due to extremely long tracks, which suggests the need for normalization or outlier handling. Explicit content also shows an imbalance, with the majority of tracks being non-explicit.\n",
    "\n",
    "We visualized several key attributes to gain insight into the dataset.  \n",
    "\n",
    "> Figure one shows the distribution of track popularity and it illustrates that popularity scores are heavily concentrated between 0 and 50, with relatively few highly popular tracks. We compared energy and danceability in a scatterplot, showing a positive relationship between the two features; this suggests energetic songs also tend to be more danceable. Figure 3 presents a boxplot of duration_ms, highlighting extreme outliers that may need filtering before training models.\n",
    "\n",
    "`Still needs to be done`\n",
    "\n",
    "These analyses helped identify useful features for classification and highlighted necessary preprocessing steps such as scaling and removing outliers. Overall, the dataset appears clean and suitable for building classification models to predict track popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results\n",
    "\n",
    " > Classification Results: This section should describe the classification approach you developed and its performance. Explain what techniques you used, briefly how you designed and implemented the classifiers, how you evaluated your classifiers’ predictive ability, and how well the classifiers performed. Thoroughly describe how you evaluated performance, the comparison results, and which classifier is “best”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    " > Conclusion: Provide a brief conclusion of your project, including a short summary of the dataset you used (and any of its inherent challenges for classification), the classification approach you developed, your classifiers’ performance, and any ideas you have on ways to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "> Acknowledgments: This is where you should cite your sources, including any data, code, or materials that are outside of the scope of CPSC 322 (including previous course projects) that you used. As per the course syllabus, you also need to acknowledge any use of AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
